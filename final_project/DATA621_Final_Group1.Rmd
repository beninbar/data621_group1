---
title: 'Final: Texas Higher Education Opportunity Project (THEOP)'
subtitle: 'Critical Thinking Group 1'
author: 'Ben Inbar, Cliff Lee, Daria Dubovskaia, David Simbandumwe, Jeff Parks'
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
# chunks
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, include=TRUE, 
message=FALSE, warning=FALSE, fig.height=5, fig.align='center')

# libraries
library(tidyverse)
library(kableExtra)
library(MASS) # glm.nb()
library(mice)
library(pscl) # zeroinfl()
library(skimr)
library(sjPlot)
library(mpath)
library(yardstick)
library(labelled)
library(haven)
library(corrplot)
library(Hmisc)
library(janitor)
library(reshape)

# ggplot
theme_set(theme_light())


# random seed
set.seed(42)
```

```{r common functions}

nice_table <- function(df){
  table <- df %>% kable %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                html_font = 'monospace',
                full_width = FALSE)
  return(table)
}

model_diag <- function(model){
  model_sum <- summary(model)
  aic <- AIC(model)
  ar2 <- model_sum$adj.r.squared
  disp <- sum(resid(model,'pearson')^2)/model$df.residual
  loglik <- logLik(model)
  
  vec <- c(ifelse(is.null(aic), NA, aic),
           ifelse(is.null(ar2), NA, ar2),
           ifelse(is.null(disp), NA, disp),
           ifelse(is.null(loglik), NA, loglik))
  
  names(vec) <- c('AIC','Adj R2','Dispersion','Log-Lik')
  return(vec)
}

factor_haven <- function(df, col_lst) {
  for (c in col_lst) {
    df[c] <- as_factor(zap_missing(df[c]))
  }
  return(df)
}

```

# Load Data

```{r}

# change to your local data dir outside the repo
local_data_dir <- '../../data/theop'
# 
# 
# # load application and transactions data frames
load(paste0(local_data_dir, '/data_model/df_applications.RData'))
load(paste0(local_data_dir, '/data_model/df_transcripts.RData'))
# 
# load("C:\\Users\\bpinb\\OneDrive\\Desktop\\Coursework\\DATA 621 Business Analytics and Data Mining\\Final project\\Data\\theop\\theop\\data_model\\df_applications.RData")
# load("C:\\Users\\bpinb\\OneDrive\\Desktop\\Coursework\\DATA 621 Business Analytics and Data Mining\\Final project\\Data\\theop\\theop\\data_model\\df_transcripts.RData")

```

```{r}
# clean application data and remove labels
app_df  <- df_applications

col_lst <- c("termdes","male","ethnic","citizenship","restype","satR","actR","testscoreR","decileR","quartile","major_field","hsprivate","hstypeR","hsinstate","hseconstatus","hslos","hscentury","admit","admit_prov","enroll","gradyear","studentid_uniq","univ","termapp","sat_not_recenteredR","admit_ut_summer")

app_df <- factor_haven(app_df,col_lst)

# clean transcripts and remove labels
transcript_df <- df_transcripts

col_lst <- c("term","semgpa","hrearn","term_major_dept","term_major_field")

transcript_df <- factor_haven(transcript_df,col_lst)

```

```{r}
#rm(df_transcripts, df_applications)
```

# Data Exploration

```{r}

app_df %>% 
  #dplyr::select(!c(source, target)) %>%
  skim() %>%
  dplyr::select(skim_variable, complete_rate, n_missing, 
                numeric.p0, numeric.p100) %>%
  dplyr::rename(variable=skim_variable, min=numeric.p0, max=numeric.p100) %>%
  mutate(complete_rate=round(complete_rate,2), 
         min=round(min,2), max=round(max,2)) %>%
  arrange(variable) %>%
  nice_table()
```

```{r}

transcript_df %>% 
  #dplyr::select(!c(source, target)) %>%
  skim() %>%
  dplyr::select(skim_variable, complete_rate, n_missing, 
                numeric.p0, numeric.p100) %>%
  dplyr::rename(variable=skim_variable, min=numeric.p0, max=numeric.p100) %>%
  mutate(complete_rate=round(complete_rate,2), 
         min=round(min,2), max=round(max,2)) %>%
  arrange(variable) %>%
  nice_table()

```

```{r distrib}

transcript_df %>% dplyr::select(where(is.numeric)) %>%
  #dplyr::select(!target) %>%
  pivot_longer(everything(),names_to = c('variables'),values_to = c('values')) %>% 
  ggplot() +
  geom_histogram(aes(x=values, y = ..density..), alpha=0.5, colour='black', linewidth=0.2) +
  #geom_density(aes(x=values), color='purple') +
  facet_wrap(vars(variables), scales="free")

```

```{r}

rcore <- rcorr(as.matrix(transcript_df %>% dplyr::select(where(is.numeric))))

coeff <- rcore$r

corrplot(coeff, tl.cex = .5, tl.col="black", method = 'color', addCoef.col = "black",type="upper", order="hclust", number.cex=0.7, diag=FALSE)

```

# Transform Data

```{r}
t_df <- transcript_df

t_df$term_num <- as.numeric(t_df$term)
#t_df <- t_df %>% mutate(id = id + 1)
t_df$term_num = t_df$term_num + 1
t_df$term_num[t_df$term_num == 2] <- 1
t_df$term_num[t_df$term_num == 6] <- 2
t_df$term_num[t_df$term_num == 7] <- 6
t_df$term_num = t_df$term_num / 10
t_df$term_num = t_df$year + t_df$term_num

avg_df <- t_df %>%
  group_by(studentid) %>%
  summarise(avg_gpa = mean(cgpa)
 )

first_df <- t_df %>%
  group_by(studentid) %>%
  slice(which.min(term_num))
  
last_df <- t_df %>%
  group_by(studentid) %>%
  slice(which.max(term_num))

merge_df <- merge(avg_df, first_df, by='studentid')

merge_df <- merge(merge_df, last_df, by='studentid', 
                  suffixes = c(".first",".last"))

merge_df <- merge(merge_df, app_df, by='studentid')

model_df <- merge_df %>% 
  dplyr::select('avg_gpa','male','ethnic','citizenship','restype','satR','testscoreR','decileR')
 
levels(model_df$citizenship) <- c(levels(model_df$citizenship),"None")
model_df$citizenship[is.na(model_df$citizenship)] <- "None"
levels(model_df$ethnic) <- c(levels(model_df$ethnic),"None")
model_df$ethnic[is.na(model_df$ethnic)] <- "None"
levels(model_df$restype) <- c(levels(model_df$restype),"None")
model_df$restype[is.na(model_df$restype)] <- "None"
levels(model_df$male) <- c(levels(model_df$male),"None")
model_df$male[is.na(model_df$male)] <- "None"

# set values
model_df$decileTop10 <- FALSE
model_df$decileTop10[as.numeric(model_df$decileR) == 1] <- TRUE
levels(model_df$decileR) <- c(levels(model_df$decileR),"None")
model_df$decileR[is.na(model_df$decileR)] <- "None"

```

```{r}

merge_df %>% 
  #dplyr::select(!c(source, target)) %>%
  skim() %>%
  dplyr::select(skim_variable, complete_rate, n_missing, 
                numeric.p0, numeric.p100) %>%
  dplyr::rename(variable=skim_variable, min=numeric.p0, 
                max=numeric.p100) %>%
  mutate(complete_rate=round(complete_rate,2), 
         min=round(min,2), max=round(max,2)) %>%
  arrange(variable) %>%
  nice_table()

```

```{r}
rcore <- rcorr(as.matrix(merge_df %>% dplyr::select(!c('year.first','year.last')) %>% dplyr::select(where(is.numeric))))

coeff <- rcore$r

corrplot(coeff, tl.cex = .8, tl.col="black", method = 'color', addCoef.col = "black", type="upper", order="hclust", number.cex=0.7, diag=FALSE)

```

### Merge dataframes.

Check for duplicates in applications and transcripts.
For applications there were duplicates for the desired year of admission, so we took the minimum desired year.
For transcripts, make sure there are no duplicates for the same semester.
We also limited to enrollment at the applied school to track progress only at schools of enrollment.

```{r}
tabyl(app_df$termdes)
#dupes <- get_dupes(app_df, studentid_uniq, enroll)

app_df <- app_df |>
  mutate(termdes_num = case_when(termdes=='Spring' ~ 1
                                 , termdes=='Summer I' ~ 2
                                 , termdes=='Summer II' ~ 3
                                 , termdes=='Fall' ~ 4)) |>
  group_by(studentid_uniq) |>
  filter(yeardes==min(yeardes)) |>
  filter(termdes_num==min(termdes_num)) |>
  filter(enroll=="Yes") |>
  ungroup()
  
#dupes <- get_dupes(transcript_df, studentid_uniq, year, term)

transcript_df <- transcript_df |>
  distinct()

# Join them together
all <- app_df |>
  left_join(transcript_df, by=c('studentid_uniq', 'univ'))
  
# tabyl(all$ethnic)
# tabyl(all$univ.x)
# tabyl(all$decileR)
# tabyl(all$gradyear)
# table(all$univ.y, all$admit)
# table(all$univ.x, all$univ.y)
# tabyl(all$admit_prov)
# tabyl(all$year)

rm(transcript_df, app_df)

```

### Cleaning

Since the goal was to determine whether the 10% rule was predictive of retention (total number of semesters), and performance (cumulative GPA), to make this easier we widened the data and removed the semester-based tabulation in favor of cumulative.

1.  Create cumulative fields for `hrearn` and total numbers of semesters.
2.  Drop `gpahrs` since this was only available for one school, Texas A&M Kingsville.
3.  Drop several other variables:
    -   `studentid` since we generated a unique id with studentid and school abbreviation.
    -   `yeardes` year of admission desired, since intuitively this would be very hard to interpret as a predictor.
    -   `satR` and `actR` since these were already coalesced in the `testscoreR` column.
    -   `termapp` application term since we wanted to be timing-agnostic.
    -   `termdes_num` since we already had the variable represented as `termdes`
    -   `semgpa` semester by semester GPA, but we were only interested in cumulative.
    -   `gradyear` year of graduation as again, we wanted to be timing-agnostic.

```{r}

cleaned <- all |>
  dplyr::select(-c(studentid.x, studentid.y, yeardes, gpahrs, satR, actR, termapp, termdes_num, semgpa)) |>
  distinct() |>
  mutate(termnum = case_when(term=='Spring' ~ 1
                                 , term=='Summer I' ~ 2
                                 , term=='Summer II' ~ 3
                                 , term=='Fall' ~ 4)) |>
  group_by(studentid_uniq) |>
  mutate(cum_hrs = sum(as.numeric(hrearn)) - n(),
         cum_terms = n(),
         enrolled_pre_98 = case_when(year<=1998 ~ "Pre"
                            , year>1998 ~ "Post"
                            , T ~ "Unknown")) |>
  filter(year==max(year)) |>    # To get maximum enrollment
  filter(termnum==max(termnum)) |>  # ... and maximum cgpa.
  filter(!(enrolled_pre_98=="Unknown")) |>  # Drop cases without term years as we do not know when this would be as it relates to the TX law.
  ungroup() |>
  dplyr::select(-c(year, term, hrearn, termnum)) |>
  dplyr::select(studentid_uniq, everything())  # Just move studentid_uniq to left index.


skim(cleaned)

cleaned <- as.data.frame(cleaned)
cleaned.m <- melt(cleaned)

cleaned.m %>% ggplot(aes(x=value)) +
  geom_density(color='#023020') +
  facet_wrap(~variable, scales = 'free') +
  theme_bw()

```

```{r}
knitr::knit_exit()
```
